{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEbJijm-fGle"
      },
      "source": [
        "# *Fundamentals of Machine Learning*\n",
        "## Linear Regression and Classification Programming Report 2\n",
        "---\n",
        "18B09790 Tanpipat Kornvik"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HePoFv7__S6Z"
      },
      "source": [
        "## 1. Training word from load_digits\n",
        "First, we will import necessary library. We also check whether we have access to a GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "65WGT1im59Ov",
        "outputId": "97dfe61c-27be-43f2-f7c3-3360931d908c"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-98e796622a9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;31m# Appease the type checker; ordinarily this binding is inserted by the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: KeyboardInterrupt: "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# GPUが使える場合は使う\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmxcDn0g_0a2"
      },
      "source": [
        "### 1.1 Import and Process Data\n",
        "we import that data that will be used in this problem from sklearn. We can also check the number of the data and the dimensionality(width*height of the image) as shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AHnta_t7_8N6"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_digits\n",
        "\n",
        "digits = load_digits()\n",
        "print(digits.data.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAviM2fmHQhK"
      },
      "source": [
        "After that, we split the data into 8:1:1 by split the data using sklearn model selection 2 times as shown below. In this process, we also have to reshape the data to add extra dimension for the channel numbers. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3N6MuS5nGk6t"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_all = digits.data #add another dimension\n",
        "y_all = digits.target\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "x_std = sc.fit_transform(x_all)\n",
        "x_all = x_std.reshape(-1,1,8,8)\n",
        "x_train, x_tmp, y_train, y_tmp = train_test_split(x_all,y_all,train_size=0.8)\n",
        "x_valid, x_test, y_valid, y_test = train_test_split(x_tmp,y_tmp,train_size=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de3TNRJIKOts"
      },
      "source": [
        "Next, we will perform transform the data into torch tensors in order to use torch. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RdayHr7IKNwJ"
      },
      "outputs": [],
      "source": [
        "x_train = torch.from_numpy(x_train).float()\n",
        "y_train = torch.from_numpy(y_train).long()\n",
        "\n",
        "x_valid = torch.from_numpy(x_valid).float()\n",
        "y_valid = torch.from_numpy(y_valid).long()\n",
        "\n",
        "x_test  = torch.from_numpy(x_test).float()\n",
        "y_test = torch.from_numpy(y_test).long()\n",
        "\n",
        "trainset = torch.utils.data.TensorDataset(x_train,y_train)\n",
        "validset = torch.utils.data.TensorDataset(x_valid,y_valid)\n",
        "testset  = torch.utils.data.TensorDataset(x_test,y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSY5I2XBP9v4"
      },
      "source": [
        "After we have the dataset, we will specify the batch size and create data loader. Batch size is the number of training examples utilized in one iteration.There is no magic number for batch size. However, it has been observed in practice that using a larger batch can degrade the quality of the model. In general, batch size of 32 is a good starting point, we can also try 64, 128, and 256."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c6D4HQAxQ7kr"
      },
      "outputs": [],
      "source": [
        "batch_size=32\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "validloader = torch.utils.data.DataLoader(validset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6Bfx1a5_glM"
      },
      "source": [
        "### 1.2 Define CNN and training function\n",
        "Next, we define the network we want to use for our classification problem. Follwing the instruction from the problem, we can define the CNN as the following configuration shown in the comment part. Lastly, We also need to send the created network to the GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gq0y8K3i_JSN"
      },
      "outputs": [],
      "source": [
        "# （CNN,Pooling）x1 (4 Filter 3x3, Pooling 2x2)，Feed Forward  x1 Network\n",
        "# Input 8x8 grayscale image\n",
        "# 1x8x8 --> 4x6x6 (3x3 conv, same padding, 4ch)\n",
        "# 4x6x6 --> 4x3x3 (2x2 max pooling)\n",
        "# 4x3x3 --> 10 (full connection)\n",
        "\n",
        "model1 = nn.Sequential(\n",
        "    nn.Conv2d(1,4,3),  # input channels,output channels,kernel_size, \n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2,2), # define pooling size\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(36,10), # apply feedforward in the end to 10 classes\n",
        ")\n",
        "\n",
        "model1 = model1.to(device) # send the network to GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcuEFqmVUZPs"
      },
      "source": [
        "After that we will create the function to train the data which can be defined as below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qavWFC_JT9Ub"
      },
      "outputs": [],
      "source": [
        "def validate(model, criterion, validloader):\n",
        "  size_valid = 0\n",
        "  loss_valid = 0\n",
        "  correct_valid = 0\n",
        "  for batch_index, (inputs, labels) in enumerate(validloader):\n",
        "    # pbar.set_description(\"[Epoch %d/%d, valid batch %d/%d]\" % (epoch_index + 1, epochs, batch_index + 1, len(validloader)))\n",
        "    \n",
        "    # send the data to GPU\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # calculate output\n",
        "    outputs = model(inputs)\n",
        "    # calculate loss\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # calculate accuracy\n",
        "    size_valid += inputs.shape[0]                 # add batch size to trained data\n",
        "    loss_valid += loss.item() * inputs.shape[0]   # calculate this batch loss\n",
        "    _, predicted = torch.max(outputs, 1)          # output the prediction\n",
        "    correct = (predicted == labels).sum().item()  # calculate how many images in the batch are predicted correctly\n",
        "    correct_valid += correct                      # add the number to the overall correct prediction\n",
        "    acc_valid = correct_valid / size_valid * 100\n",
        "    loss_valid /= size_valid\n",
        "    # pbar.set_postfix({'loss': (\"%.3f\" % (loss_valid / size_valid)),\n",
        "    #                   'acc%': (\"%.1f\" % (correct_valid / size_valid * 100)),})\n",
        "  \n",
        "  return loss_valid, acc_valid\n",
        "def train(model,criterion,optimizer, trainloader, validloader, epochs):\n",
        "  # use tqdm to print to progress bar\n",
        "  correct_train = 0\n",
        "  size_train = 0\n",
        "  loss_train = 0\n",
        "  with tqdm(range(epochs)) as pbar:\n",
        "      for epoch_index in pbar:\n",
        "          loss_train, size_train, correct_train = 0.0, 0, 0 \n",
        "          # train with each batch of the data \n",
        "          for batch_index, (inputs, labels) in enumerate(trainloader):\n",
        "              pbar.set_description(\"[Epoch %d/%d, train batch %d/%d]\" % (epoch_index + 1, epochs, batch_index + 1, len(trainloader)))\n",
        "\n",
        "              # send that data for GPU for calculation\n",
        "              inputs = inputs.to(device)\n",
        "              labels = labels.to(device)\n",
        "\n",
        "              # Set the gradient inside the optimizor as 0\n",
        "              optimizer.zero_grad()\n",
        "              # calculate the output using the model\n",
        "              outputs = model(inputs)\n",
        "              # calculate loss using given loss function\n",
        "              loss = criterion(outputs, labels)\n",
        "              # calculate the gradient of each parameter and work the loss backward to the previous layer\n",
        "              loss.backward()\n",
        "              # update the weight from backpropagation\n",
        "              optimizer.step()\n",
        "\n",
        "              # calculate accuracy of the model on training data\n",
        "              # add batch size to trained data\n",
        "              size_train += inputs.shape[0]                 # add batch size to trained data \n",
        "              #(each time the model is updated, we trained data equals to the number of batch size)\n",
        "              loss_train += loss.item() * inputs.shape[0]   # calculate this batch loss\n",
        "              _, predicted = torch.max(outputs, 1)          # output the prediction\n",
        "              correct = (predicted == labels).sum().item()  # calculate how many images in the batch are predicted correctly\n",
        "              correct_train += correct                      # add the number to the overall correct prediction\n",
        "              pbar.set_postfix({'loss': (\"%.3f\" % (loss_train / size_train)),\n",
        "                                'acc%': (\"%.1f\" % (correct_train / size_train * 100)),})\n",
        "           # calculate this epoch accuracy\n",
        "          loss_train /= size_train\n",
        "          acc_train = correct_train / size_train * 100\n",
        "          # validate the trained model with validloader and calculate the accuracy\n",
        "          model.eval()   \n",
        "          loss_valid, acc_valid = validate(model, criterion, validloader)\n",
        "\n",
        "          if (epoch_index+1)%10 == 0:\n",
        "            print(\"epoch %d, train loss %.4f, train acc %.1f%%, valid loss %.4f, valid acc %.1f%%\" %\n",
        "                (epoch_index + 1, loss_train, acc_train, loss_valid, acc_valid))\n",
        "\n",
        "  print('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FBzH0EPTUjn"
      },
      "source": [
        "Next, we will define loss function and optimizer for training the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ef4wOAWfR5N4"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Use cross entropy as loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Use adam as optimizer\n",
        "optimizer = optim.Adam(model1.parameters(), lr=0.001, betas=(0.9, 0.999))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Gc92R5cZgJf"
      },
      "source": [
        "Finally, we can train the model using the defined training function, loss function, optimizer, and the processed dataset. Here we will let epochs equal to 100."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5eVF__-SThxM"
      },
      "outputs": [],
      "source": [
        "epochs = 100\n",
        "train(model1,criterion,optimizer, trainloader, validloader, epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxYtUoePfPJN"
      },
      "source": [
        "### 1.3 Calculate accuracy with test data\n",
        "We can easily can calculate the accuracy of the trained model with the test data by using the predefined validate function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9jE6ViekZ8bf"
      },
      "outputs": [],
      "source": [
        "model1.eval()\n",
        "loss_test, acc_test = validate(model1, criterion, testloader)\n",
        "print(f\"test_accuracy: {acc_test}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vegKzyjQg9Bl"
      },
      "source": [
        "## 2. [Optional] Test with another model\n",
        "### 2.1 Training data with new model\n",
        "Using the same process above, we create different model, defined below, to train the data. This time we will also used different optimizer to increase the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2kSjLekjgeOe"
      },
      "outputs": [],
      "source": [
        "# （CNN,Pooling）x2 (4 Filter 3x3, Pooling 2x2)，Feed Forward  x1 Network\n",
        "# Input 8x8 grayscale image\n",
        "# 1x8x8 --> 4x6x6 (3x3 conv, no padding, 4ch)\n",
        "# 4x6x6 --> 4x3x3 (2x2 max pooling)\n",
        "# 4x3x3 --> 30x1x1 (3x3 conv, no padding, 30ch)\n",
        "# 30x1x1 --> 10 (full connection)\n",
        "\n",
        "model2 = nn.Sequential(\n",
        "    nn.Conv2d(1,4,3),  # input channels,output channels,kernel_size, \n",
        "    # nn.ReLU(),\n",
        "    nn.MaxPool2d(2,2), # define pooling size\n",
        "    nn.Conv2d(4,30,3),  # input channels,output channels,kernel_size, \n",
        "    nn.Flatten(),\n",
        "    nn.Linear(30,10), # apply feedforward in the end to 10 classes\n",
        ")\n",
        "\n",
        "model2 = model2.to(device) # send the network to GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xIcHpenniR_B"
      },
      "outputs": [],
      "source": [
        "epochs = 100\n",
        "optimizer2 = torch.optim.SGD(model2.parameters(), lr=0.001, momentum=0.9)\n",
        "train(model2,criterion,optimizer2, trainloader, validloader, epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbykIbNNk5pQ"
      },
      "source": [
        "### 2.2 Evaluating the result\n",
        "The result of the new model with SDG optimizer as shown as below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "e71OPH8ijJ8O"
      },
      "outputs": [],
      "source": [
        "model2.eval()\n",
        "loss_test, acc_test = validate(model2, criterion, testloader)\n",
        "print(f\"test_accuracy: {acc_test}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M714RkM9lKQX"
      },
      "source": [
        "We can cleary see that the model clearly perform better than the previous one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dvzySX_mDMx"
      },
      "source": [
        "## 3. [Optional] Showing images that are misclassified"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ9qA7o4tWcJ"
      },
      "source": [
        "We can reuse the code in the train function to predict the outcome of model1. However, we will try to find the predictions that are incorrect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZFZUrmIft3S-"
      },
      "outputs": [],
      "source": [
        "output = model1(x_test.to(device))\n",
        "labels = y_test.to(device)\n",
        "_, predicted = torch.max(output, 1)          # output the prediction\n",
        "incorrect = (predicted != labels)            # find the incorrect prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "150xl_ZKuRUp"
      },
      "source": [
        "After we know which prediction is wrong, we can map that back to find the corresponging images and their true output as shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wO6DSL3FlIfv"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1,5,figsize=(15,10))\n",
        "num_incor = 0 # variable to count number of incorrect prediction\n",
        "for i, val in enumerate(incorrect):\n",
        "  if(val): # for each incorrect prediction, plot the image \n",
        "    image = x_test[i].reshape(8,8).cpu().numpy() # i is the index of image that the prediction went wrong\n",
        "    axs[num_incor].imshow(image, cmap=plt.cm.gray_r) \n",
        "    axs[num_incor].title.set_text(f'Real: {y_test[i]}, Predicted: {predicted[i]}')\n",
        "    num_incor += 1\n",
        "    if(num_incor>=5):\n",
        "      break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtGtgkcfpySo"
      },
      "source": [
        "## 4. [Optional] Fashion MNIST database\n",
        "### 4.1 Train the model\n",
        "In this last part, we will train the data from Fashion MNIST which contrains 10 different classes of clothes images. We have to be careful that the image's size is 28x28. Here we will also perform nomalization on the images as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cT1vQWdEn2nO"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "# define transformation to normalize data\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, ), (0.5, ))])\n",
        "\n",
        "# downlod train and test data \n",
        "batch_size=256\n",
        "trainset = datasets.FashionMNIST(root=\"./\", train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "validset = datasets.FashionMNIST(root=\"./\", train=False, download=True, transform=transform)\n",
        "validloader = torch.utils.data.DataLoader(validset, batch_size=batch_size, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ic29_z1wX45"
      },
      "source": [
        "The images from fashionMNIST can be seen below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bNmxnNkkvnhk"
      },
      "outputs": [],
      "source": [
        "# Images\n",
        "fig, ax = plt.subplots(1, 5, figsize=(15, 6), sharex='col', sharey='row')\n",
        "for j in range(5):\n",
        "    ax[j].imshow(trainset.data[j], cmap=plt.cm.gray_r)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7zKV1YpClxT"
      },
      "source": [
        "We also know that each training and test example is assigned to one of the following labels:\n",
        "*   0 T-shirt/top\n",
        "*   1 Trouser\n",
        "*   2 Pullover\n",
        "*   3 Dress\n",
        "*   4 Coat\n",
        "*   5 Sandal\n",
        "*   6 Shirt\n",
        "*   7 Sneaker\n",
        "*   8 Bag\n",
        "*   9 Ankle boot\n",
        "\n",
        "Thus we can create a mapping from index to text label by defining the following array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wpxb33CWC2IN"
      },
      "outputs": [],
      "source": [
        "text_labels = [\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vAKX-gOxNXW"
      },
      "source": [
        "Next we will define some complex CNN in order to classify this dataset. We will try to use 2 different convolutional layers to do this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZpL2GInOwe2b"
      },
      "outputs": [],
      "source": [
        "# （CNN,Pooling) (2 Filter (3x3,5x5), 2 Pooling (2x2,3x3))，Feed Forward  x1 Network\n",
        "# Input 28x28 grayscale image\n",
        "# 1x28x28 --> 16x26x26 (3x3 conv, no padding, 16ch)\n",
        "# 16x26x26 -->16x13x13 (2x2 max pooling)\n",
        "# 16x13x13 --> 32x9x9 (5x5 conv, no padding, 32ch)\n",
        "# 32x9x9 -->32x3x3 (3x3 max pooling)\n",
        "# 32x3x3 -->100 (2full connection)\n",
        "# 100 --> 40 (full connection)\n",
        "# 40 --> 10 (full connection)\n",
        "\n",
        "model3 = nn.Sequential(\n",
        "    nn.Conv2d(1,16,3),  # input channels,output channels,kernel_size, \n",
        "    nn.ReLU(inplace=True), \n",
        "    nn.MaxPool2d(2,2), # define pooling size\n",
        "    nn.Conv2d(16,32,5), \n",
        "    nn.ReLU(inplace=True), \n",
        "    nn.MaxPool2d(3,3),  \n",
        "    nn.Flatten(),\n",
        "    nn.Linear(32*3*3,100), \n",
        "    nn.ReLU(inplace=True), \n",
        "    nn.Linear(100,40), \n",
        "    nn.ReLU(inplace=True), \n",
        "    nn.Linear(40,10), # apply feedforward in the end to 10 classes\n",
        ")\n",
        "\n",
        "model3 = model3.to(device) # send the network to GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5qDoqMYp0Skc"
      },
      "outputs": [],
      "source": [
        "epochs = 30\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizor3 = torch.optim.SGD(model3.parameters(),lr=0.05)\n",
        "train(model3, criterion, optimizor3, trainloader, validloader, epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kbqmqzk54Va-"
      },
      "source": [
        "### 4.2 Accuracy\n",
        "The accuracy tested with the test data is as below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "a5thMPiV0kyl"
      },
      "outputs": [],
      "source": [
        "model3.eval()\n",
        "loss_test, acc_test = validate(model3, criterion, validloader)\n",
        "print(f\"test_accuracy: {acc_test}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lME8Ax3E927h"
      },
      "source": [
        "### 4.3 Showing images that are misclassified\n",
        "Since the data is very big and is not processed like the one in the previous section, using the same method to label and retreive incorrect result might not work well. As a result, we can loop the data to extract the incorrect result instead as the following code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Sd98-bP89pR4"
      },
      "outputs": [],
      "source": [
        "for batch_index, (inputs, labels) in enumerate(validloader):\n",
        "  # send that data for GPU for calculation\n",
        "  inputs = inputs.to(device)\n",
        "  labels = labels.to(device)\n",
        "\n",
        "  # calculate the output using the model\n",
        "  outputs = model3(inputs)\n",
        "  _, predicted = torch.max(outputs, 1)          # output the prediction\n",
        "  incorrect = (predicted != labels)            # find the incorrect prediction\n",
        "  num_incorrect = torch.sum(incorrect)\n",
        "  correct_labels = labels[incorrect].cpu().detach().numpy()\n",
        "  predicted_labels = predicted[incorrect].cpu().detach().numpy()\n",
        "  imgs = inputs[incorrect].cpu().detach().numpy().reshape((-1,28,28))\n",
        "  if num_incorrect>=5:\n",
        "    fig, axs = plt.subplots(1,5,figsize=(20,10))\n",
        "    for i, val in enumerate(correct_labels):\n",
        "      # if(val): # for each incorrect prediction, plot the image \n",
        "        axs[i].imshow(imgs[i], cmap=plt.cm.gray_r) \n",
        "        axs[i].title.set_text(f'Real: {text_labels[correct_labels[i]]}, Predicted: {text_labels[predicted_labels[i]]}')\n",
        "        if i==4:\n",
        "          break\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RhMw4ccpBFQZ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Fundamental of Machine Learning 2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}